steps,num_train_epochs,per_device_train_batch_size,gradient_accumulation_steps,optim,save_steps,logging_steps,learning_rate,weight_decay,fp16,bf16,max_grad_norm,max_steps,warmup_ratio,group_by_length,lr_scheduler_type
1000,2,4,1,paged_adamw_32bit,25,25,0.0002,0.001,False,True,0.3,-1,0.03,True,constant
